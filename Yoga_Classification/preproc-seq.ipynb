{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "8bb395b7-98aa-4727-bfbf-7f1c8dea9893"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "6c5d47e1-1811-4507-aaed-56760af68fc5"
    }
   },
   "outputs": [],
   "source": [
    "#creating training & test data file: 18*2*45*n => 30 frame overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asanas = [\"bhujangasan\", \"padamasan\", \"shavasan\", \"tadasan\", \"trikonasan\", \"vrikshasan\"]\n",
    "data_path = r\"C:\\Users\\HP\\Desktop\\EE655 Project\\Yoga-Pose-detection-and-feedback-generation\\dataset\\yoga_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\EE655 Project\\Yoga-Pose-detection-and-feedback-generation\\dataset\\yoga_data\\bhujangasan\n",
      "\n",
      "🧘‍♀️ BHUJANGASAN — 16 files found\n",
      "📂 Sample file: 10_Pranshul_Bhuj.json\n",
      "✅ Loaded sample JSON with type: <class 'list'> and shape-like info: [124 frames]\n",
      "C:\\Users\\HP\\Desktop\\EE655 Project\\Yoga-Pose-detection-and-feedback-generation\\dataset\\yoga_data\\padamasan\n",
      "\n",
      "🧘‍♀️ PADAMASAN — 14 files found\n",
      "📂 Sample file: 10_Rakesh_Padam.json\n",
      "✅ Loaded sample JSON with type: <class 'list'> and shape-like info: [142 frames]\n",
      "C:\\Users\\HP\\Desktop\\EE655 Project\\Yoga-Pose-detection-and-feedback-generation\\dataset\\yoga_data\\shavasan\n",
      "\n",
      "🧘‍♀️ SHAVASAN — 15 files found\n",
      "📂 Sample file: 10_Pranshul_Shav.json\n",
      "✅ Loaded sample JSON with type: <class 'list'> and shape-like info: [135 frames]\n",
      "C:\\Users\\HP\\Desktop\\EE655 Project\\Yoga-Pose-detection-and-feedback-generation\\dataset\\yoga_data\\tadasan\n",
      "\n",
      "🧘‍♀️ TADASAN — 15 files found\n",
      "📂 Sample file: 10_Pranshul_Tad.json\n",
      "✅ Loaded sample JSON with type: <class 'list'> and shape-like info: [122 frames]\n",
      "C:\\Users\\HP\\Desktop\\EE655 Project\\Yoga-Pose-detection-and-feedback-generation\\dataset\\yoga_data\\trikonasan\n",
      "\n",
      "🧘‍♀️ TRIKONASAN — 13 files found\n",
      "📂 Sample file: 10_Rakesh_Trik.json\n",
      "✅ Loaded sample JSON with type: <class 'list'> and shape-like info: [144 frames]\n",
      "C:\\Users\\HP\\Desktop\\EE655 Project\\Yoga-Pose-detection-and-feedback-generation\\dataset\\yoga_data\\vrikshasan\n",
      "\n",
      "🧘‍♀️ VRIKSHASAN — 15 files found\n",
      "📂 Sample file: 10_Pranshul_Vriksh.json\n",
      "✅ Loaded sample JSON with type: <class 'list'> and shape-like info: [123 frames]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Dictionary to store parsed JSON samples\n",
    "asana_data_preview = {}\n",
    "\n",
    "# Iterate over each asana folder\n",
    "for asana in asanas:\n",
    "    asana_folder = os.path.join(data_path, asana)\n",
    "    print(asana_folder)\n",
    "    \n",
    "    if not os.path.exists(asana_folder):\n",
    "        print(f\"⚠️ Folder not found for {asana}\")\n",
    "        continue\n",
    "    \n",
    "    json_files = [f for f in os.listdir(asana_folder) if f.endswith('.json')]\n",
    "    print(f\"\\n🧘‍♀️ {asana.upper()} — {len(json_files)} files found\")\n",
    "    \n",
    "    # Load first JSON file as a sample\n",
    "    if json_files:\n",
    "        sample_path = os.path.join(asana_folder, json_files[0])\n",
    "        with open(sample_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            asana_data_preview[asana] = data  # Save for later use or visualization\n",
    "            \n",
    "        print(f\"📂 Sample file: {json_files[0]}\")\n",
    "        print(f\"✅ Loaded sample JSON with type: {type(data)} and shape-like info: [{len(data)} frames]\")\n",
    "    else:\n",
    "        print(\"❌ No JSON files found.\")\n",
    "\n",
    "# Optional: access a specific sample's content\n",
    "# print(json.dumps(asana_data_preview['tadasan'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "#list of asanas, each asana has all it's videos, each video has list of stacked 18*2 numpy arrays\n",
    "val_list = []\n",
    "test_list = []\n",
    "# print(\"ok\")\n",
    "for a in asanas:\n",
    "    print(\"ok\")\n",
    "    currAsanaTrain = []\n",
    "    currAsanaVal = []\n",
    "    currAsanaTest = []\n",
    "    path = data_path + \"\\\\\" +  a\n",
    "    for i in range(1,17):\n",
    "        # print(\"ok\")\n",
    "        currVideo = []\n",
    "        start =  str(i) + \"_\"\n",
    "        for filename in os.listdir(path):\n",
    "            data = []\n",
    "            # print(i)\n",
    "            if filename.startswith(start):\n",
    "                #get data from file\n",
    "                # print(\"o\")\n",
    "                with open(path + \"\\\\\" + filename) as json_data:\n",
    "                    # print(\"ok1\")\n",
    "                    d = json.load(json_data)\n",
    "                    # print(d)\n",
    "                    npdata = np.asarray(d)\n",
    "                    # print(npdata.shape)\n",
    "                    # print(npdata.shape)\n",
    "                    Xdata = npdata[:,:,0]\n",
    "                    Ydata = npdata[:,:,1]\n",
    "                    # print(len(Ydata))\n",
    "                    # print(Xdata)\n",
    "                    stk = np.dstack((Xdata, Ydata)) #stack vertically\n",
    "                    currVideo.append(stk)\n",
    "                    # print(stk)\n",
    "                # print(\"ok\")\n",
    "        #print currVideo\n",
    "        if a == 'vrikshasan' and i == 15:\n",
    "            # this one has difference and creates noise\n",
    "            currAsanaTrain.append(currVideo)\n",
    "        elif (i+1)%5 == 0 and len(currVideo) != 0:\n",
    "            currAsanaTest.append(currVideo)\n",
    "        elif (i)%5 == 0 and len(currVideo) != 0:\n",
    "            currAsanaVal.append(currVideo)\n",
    "        elif len(currVideo) != 0:\n",
    "            currAsanaTrain.append(currVideo)\n",
    "        # break\n",
    "        # print(\"0\")\n",
    "    train_list.append(currAsanaTrain)\n",
    "    val_list.append(currAsanaVal)\n",
    "    test_list.append(currAsanaTest)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n",
      "1\n",
      "54\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(train_list))\n",
    "print(len(train_list[0]))\n",
    "print(len(train_list[0][0]))\n",
    "print(len(train_list[0][0][0]))\n",
    "print(len(train_list[0][0][0][0]))\n",
    "# len(test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten_list = (train_list[0][0])\n",
    "# nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "# flattened_list = [item for sublist in train_list for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list[1] = [item for sublist in train_list[1] for item in sublist]\n",
    "# train_list[0] = [item for sublist in train_list[0] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "140\n",
      "121\n",
      "146\n",
      "126\n",
      "125\n",
      "177\n",
      "81\n",
      "92\n",
      "147\n",
      "86\n",
      "133\n",
      "133\n",
      "128\n",
      "131\n",
      "125\n",
      "76\n",
      "140\n",
      "132\n",
      "130\n",
      "159\n",
      "123\n",
      "126\n",
      "160\n",
      "129\n",
      "196\n",
      "90\n",
      "92\n",
      "151\n",
      "155\n",
      "122\n",
      "126\n",
      "128\n",
      "125\n",
      "153\n",
      "91\n",
      "162\n",
      "132\n",
      "151\n",
      "126\n",
      "140\n",
      "137\n",
      "124\n",
      "124\n",
      "122\n",
      "147\n",
      "177\n",
      "155\n",
      "153\n",
      "146\n",
      "134\n",
      "126\n",
      "156\n",
      "154\n",
      "160\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "#videos in datset are 30 fps\n",
    "window_size = 10 # number of frames in 1 test case\n",
    "# overlap_size = 36 # overlap between two testcase\n",
    "train_cases = []\n",
    "train_labels = []\n",
    "sum=0\n",
    "for i, asana in enumerate(train_list):\n",
    "    for vid in asana:\n",
    "        vid = vid[0]\n",
    "        # window_size = ok\n",
    "        print(len((vid)))\n",
    "        sum+=len((vid))\n",
    "        for start in range(0, len(vid) - window_size + 1):  # Adjusted the range to prevent IndexError\n",
    "            currCase = np.empty([window_size,33,2])  # Updated shape to match vid\n",
    "            for index in range(0, window_size):\n",
    "                if(start+index >= len(vid)):\n",
    "                    break # Added this line to prevent IndexError\n",
    "                currCase[index] = vid[start+index]\n",
    "            train_cases.append(currCase)\n",
    "            train_labels.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6896\n",
      "6896\n"
     ]
    }
   ],
   "source": [
    "if train_cases and train_labels:\n",
    "    print(len(train_cases))\n",
    "    print(len(train_labels))\n",
    "else:\n",
    "    print(\"train_cases or train_labels is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = []\n",
    "test_labels = []\n",
    "\n",
    "for i, asana in enumerate(test_list):\n",
    "    for vid in asana:\n",
    "        vid = vid[0]\n",
    "        for start in range(0, len(vid) - window_size + 1):\n",
    "            currCase = np.empty([window_size,33,2])\n",
    "            for index in range(0,window_size):\n",
    "                if(start+index >= len(vid)):\n",
    "                    break # Added this line to prevent IndexError\n",
    "                currCase[index] = vid[start+index]\n",
    "            test_cases.append(currCase)\n",
    "            test_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2030\n",
      "2030\n"
     ]
    }
   ],
   "source": [
    "print (len(test_cases))\n",
    "print (len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cases = []\n",
    "val_labels = []\n",
    "for i, asana in enumerate(val_list):\n",
    "    for vid in asana:\n",
    "        vid = vid[0]\n",
    "        for start in range(0, len(vid) - window_size + 1):\n",
    "            currCase = np.empty([window_size,33,2])\n",
    "            for index in range(0,window_size):\n",
    "                if(start+index >= len(vid)):\n",
    "                    break # Added this line to prevent IndexError\n",
    "                currCase[index] = vid[start+index]\n",
    "            val_cases.append(currCase)\n",
    "            val_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2092\n",
      "2092\n"
     ]
    }
   ],
   "source": [
    "print (len(val_cases))\n",
    "print (len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array and save\n",
    "train_arr = np.empty([len(train_cases), window_size, 33, 2])\n",
    "for i, ele in enumerate(train_cases):\n",
    "    train_arr[i] = ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.empty([len(test_cases), window_size, 33, 2])\n",
    "for i, ele in enumerate(test_cases):\n",
    "    test_arr[i] = ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_arr = np.empty([len(val_cases), window_size, 33, 2])\n",
    "for i, ele in enumerate(val_cases):\n",
    "    val_arr[i] = ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"trainX\", train_arr)\n",
    "np.save(\"testX\", test_arr)\n",
    "np.save(\"valX\", val_arr)\n",
    "np.save(\"trainY\", np.asarray(train_labels))\n",
    "np.save(\"testY\", np.asarray(test_labels))\n",
    "np.save(\"valY\", np.asarray(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
